Version 1
This system takes the sensors and splits them into a training set and a testing set. The sensors are assumed to have a  time series of scalars as well as one or more properties (like elevation) that are static with respect to time. A rule (neural network) for turning the time series into the static values is generated by starting with a random rule and repeatedly modifying it to improve its accuracy on the training set. Once this rule is found the algorithm tests the rule on the test sensors to test that the correlation appears in all the sensors, and the degree form which the fixed properties can be deduced from the time sequences is measured. This should be able to capture any rule that allows the static value to be predicted from the time series.

In version 2 the network is expected to generate the error in its guess as well as the value. The network is penalized for being uncertain, but penalised more for being certain and wrong. The main advantage of such a network is that it is able to pull out subsets of the data with a strong pattern in. Those will be sensors for which the networks predicted error (the error bars the network puts on its own figures) was low. Using the networks actual error would mean that it sometimes got it right by luck when it didn't have a clue. It also spots a stronger pattern in such data.

Network 3 should be able to say that the value is either exactly here or around there. Giving multiple likely values for the static values. (not working yet)
